{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f318509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math , copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671ce6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Stats_from</th>\n",
       "      <th>Age</th>\n",
       "      <th>MPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>PER</th>\n",
       "      <th>TOPG</th>\n",
       "      <th>PFG</th>\n",
       "      <th>2017_2018 Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quincy Acy</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.287304</td>\n",
       "      <td>-0.963811</td>\n",
       "      <td>-0.834424</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>-1.081728</td>\n",
       "      <td>-0.262381</td>\n",
       "      <td>-0.885161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-1.014346</td>\n",
       "      <td>0.263455</td>\n",
       "      <td>-0.348183</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>-0.337766</td>\n",
       "      <td>1.331825</td>\n",
       "      <td>1.737947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arron Afflalo</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.924431</td>\n",
       "      <td>1.240197</td>\n",
       "      <td>0.510925</td>\n",
       "      <td>-0.771221</td>\n",
       "      <td>-0.205984</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>-0.806942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexis Ajinca</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.197390</td>\n",
       "      <td>-0.994023</td>\n",
       "      <td>-0.699399</td>\n",
       "      <td>-0.162314</td>\n",
       "      <td>-0.506993</td>\n",
       "      <td>0.541693</td>\n",
       "      <td>-0.474272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.197390</td>\n",
       "      <td>-1.143741</td>\n",
       "      <td>-0.787815</td>\n",
       "      <td>1.412445</td>\n",
       "      <td>-0.316834</td>\n",
       "      <td>0.611292</td>\n",
       "      <td>-0.178865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Joe Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.771999</td>\n",
       "      <td>-1.615213</td>\n",
       "      <td>-1.090642</td>\n",
       "      <td>-0.981189</td>\n",
       "      <td>-0.645615</td>\n",
       "      <td>-1.814225</td>\n",
       "      <td>-0.915249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Nick Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.924431</td>\n",
       "      <td>-0.454942</td>\n",
       "      <td>-0.470467</td>\n",
       "      <td>-1.149164</td>\n",
       "      <td>-0.958740</td>\n",
       "      <td>-1.517006</td>\n",
       "      <td>-0.445188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.197390</td>\n",
       "      <td>1.190077</td>\n",
       "      <td>0.916875</td>\n",
       "      <td>0.614567</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>0.881372</td>\n",
       "      <td>0.768220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.771999</td>\n",
       "      <td>0.159638</td>\n",
       "      <td>-0.208376</td>\n",
       "      <td>0.320612</td>\n",
       "      <td>-0.486582</td>\n",
       "      <td>1.342569</td>\n",
       "      <td>0.488747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Tyler Zeller</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.044957</td>\n",
       "      <td>-1.321992</td>\n",
       "      <td>-0.681595</td>\n",
       "      <td>0.173634</td>\n",
       "      <td>-0.693605</td>\n",
       "      <td>-0.459941</td>\n",
       "      <td>-0.885161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player  Stats_from       Age       MPG       PPG       PER  \\\n",
       "0        Quincy Acy      2016.0 -0.287304 -0.963811 -0.834424  0.026657   \n",
       "1      Steven Adams      2016.0 -1.014346  0.263455 -0.348183  0.194631   \n",
       "2     Arron Afflalo      2016.0  0.924431  1.240197  0.510925 -0.771221   \n",
       "3     Alexis Ajinca      2016.0  0.197390 -0.994023 -0.699399 -0.162314   \n",
       "4      Cole Aldrich      2016.0  0.197390 -1.143741 -0.787815  1.412445   \n",
       "..              ...         ...       ...       ...       ...       ...   \n",
       "340       Joe Young      2016.0 -0.771999 -1.615213 -1.090642 -0.981189   \n",
       "341      Nick Young      2016.0  0.924431 -0.454942 -0.470467 -1.149164   \n",
       "342  Thaddeus Young      2016.0  0.197390  1.190077  0.916875  0.614567   \n",
       "343     Cody Zeller      2016.0 -0.771999  0.159638 -0.208376  0.320612   \n",
       "344    Tyler Zeller      2016.0 -0.044957 -1.321992 -0.681595  0.173634   \n",
       "\n",
       "         TOPG       PFG  2017_2018 Salary  \n",
       "0   -1.081728 -0.262381         -0.885161  \n",
       "1   -0.337766  1.331825          1.737947  \n",
       "2   -0.205984  0.126687         -0.806942  \n",
       "3   -0.506993  0.541693         -0.474272  \n",
       "4   -0.316834  0.611292         -0.178865  \n",
       "..        ...       ...               ...  \n",
       "340 -0.645615 -1.814225         -0.915249  \n",
       "341 -0.958740 -1.517006         -0.445188  \n",
       "342  0.683300  0.881372          0.768220  \n",
       "343 -0.486582  1.342569          0.488747  \n",
       "344 -0.693605 -0.459941         -0.885161  \n",
       "\n",
       "[345 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba = pd.read_csv('vised_zscaled_nba_stats_salaries_2017_2018.csv')\n",
    "\n",
    "nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e4613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>MPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>PER</th>\n",
       "      <th>TOPG</th>\n",
       "      <th>PFG</th>\n",
       "      <th>2017_2018 Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.287304</td>\n",
       "      <td>-0.963811</td>\n",
       "      <td>-0.834424</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>-1.081728</td>\n",
       "      <td>-0.262381</td>\n",
       "      <td>-0.885161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.014346</td>\n",
       "      <td>0.263455</td>\n",
       "      <td>-0.348183</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>-0.337766</td>\n",
       "      <td>1.331825</td>\n",
       "      <td>1.737947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924431</td>\n",
       "      <td>1.240197</td>\n",
       "      <td>0.510925</td>\n",
       "      <td>-0.771221</td>\n",
       "      <td>-0.205984</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>-0.806942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197390</td>\n",
       "      <td>-0.994023</td>\n",
       "      <td>-0.699399</td>\n",
       "      <td>-0.162314</td>\n",
       "      <td>-0.506993</td>\n",
       "      <td>0.541693</td>\n",
       "      <td>-0.474272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197390</td>\n",
       "      <td>-1.143741</td>\n",
       "      <td>-0.787815</td>\n",
       "      <td>1.412445</td>\n",
       "      <td>-0.316834</td>\n",
       "      <td>0.611292</td>\n",
       "      <td>-0.178865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.771999</td>\n",
       "      <td>-1.615213</td>\n",
       "      <td>-1.090642</td>\n",
       "      <td>-0.981189</td>\n",
       "      <td>-0.645615</td>\n",
       "      <td>-1.814225</td>\n",
       "      <td>-0.915249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.924431</td>\n",
       "      <td>-0.454942</td>\n",
       "      <td>-0.470467</td>\n",
       "      <td>-1.149164</td>\n",
       "      <td>-0.958740</td>\n",
       "      <td>-1.517006</td>\n",
       "      <td>-0.445188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.197390</td>\n",
       "      <td>1.190077</td>\n",
       "      <td>0.916875</td>\n",
       "      <td>0.614567</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>0.881372</td>\n",
       "      <td>0.768220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.771999</td>\n",
       "      <td>0.159638</td>\n",
       "      <td>-0.208376</td>\n",
       "      <td>0.320612</td>\n",
       "      <td>-0.486582</td>\n",
       "      <td>1.342569</td>\n",
       "      <td>0.488747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.044957</td>\n",
       "      <td>-1.321992</td>\n",
       "      <td>-0.681595</td>\n",
       "      <td>0.173634</td>\n",
       "      <td>-0.693605</td>\n",
       "      <td>-0.459941</td>\n",
       "      <td>-0.885161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age       MPG       PPG       PER      TOPG       PFG  \\\n",
       "0   -0.287304 -0.963811 -0.834424  0.026657 -1.081728 -0.262381   \n",
       "1   -1.014346  0.263455 -0.348183  0.194631 -0.337766  1.331825   \n",
       "2    0.924431  1.240197  0.510925 -0.771221 -0.205984  0.126687   \n",
       "3    0.197390 -0.994023 -0.699399 -0.162314 -0.506993  0.541693   \n",
       "4    0.197390 -1.143741 -0.787815  1.412445 -0.316834  0.611292   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "340 -0.771999 -1.615213 -1.090642 -0.981189 -0.645615 -1.814225   \n",
       "341  0.924431 -0.454942 -0.470467 -1.149164 -0.958740 -1.517006   \n",
       "342  0.197390  1.190077  0.916875  0.614567  0.683300  0.881372   \n",
       "343 -0.771999  0.159638 -0.208376  0.320612 -0.486582  1.342569   \n",
       "344 -0.044957 -1.321992 -0.681595  0.173634 -0.693605 -0.459941   \n",
       "\n",
       "     2017_2018 Salary  \n",
       "0           -0.885161  \n",
       "1            1.737947  \n",
       "2           -0.806942  \n",
       "3           -0.474272  \n",
       "4           -0.178865  \n",
       "..                ...  \n",
       "340         -0.915249  \n",
       "341         -0.445188  \n",
       "342          0.768220  \n",
       "343          0.488747  \n",
       "344         -0.885161  \n",
       "\n",
       "[345 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.drop(columns=['Player', 'Stats_from'], axis=1, inplace=True)\n",
    "\n",
    "nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d491b7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = nba['2017_2018 Salary']\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a0a7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_X = nba.drop('2017_2018 Salary',axis = 1)\n",
    "\n",
    "X_train = nba_X.to_numpy()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f02ac3",
   "metadata": {},
   "source": [
    "# Cost Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688486fa",
   "metadata": {},
   "source": [
    "    J(w,b) = 1/2m( f_wb(x ^ i) - y ^ i) ^ 2  ;  i = 0..m - 1\n",
    "\n",
    "    ve f_wb(x) = w * x[i] + b olmak Ã¼zere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e52528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           \n",
    "        cost += (f_wb_i - y[i])**2     \n",
    "    \n",
    "    cost /= (2 * m)                      \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59e2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2898014793280912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_test = 0.2\n",
    "w_test = np.array([0.1 , 0.2 , 0.22 , 0.5 , -0.025 , -0.01])\n",
    "compute_cost(X_train,y_train,w_test,b_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42164bad",
   "metadata": {},
   "source": [
    "# Gradient Descent AlgoritmasÄ±:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28993eaf",
   "metadata": {},
   "source": [
    "yakÄ±nsama olana kadar tekrar et : {\n",
    "\n",
    "    w_j = w_j - a * (dJ(w,b) / dw_j)  ; j = 0..n - 1 (n = feature sayÄ±sÄ± , a = learning rate alpha)\n",
    "\n",
    "    b = b - a * (dJ(w,b) / db)                     (w_j ve b aynÄ± anda update edilecek(simultaneously))\n",
    "\n",
    "}\n",
    "\n",
    "ve \n",
    "\n",
    "    (dJ(w,b) / dw_j) = 1/m( f_wb(x ^ i) - y ^ i)x_j ^ i  ; i = 0..m - 1\n",
    "\n",
    "    (dJ(w,b) / db) =  1/m( f_wb(x ^ i) - y ^ i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "954e0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent formÃ¼llerindeki tÃ¼revli kÄ±sÄ±mlarÄ± hesaplar\n",
    "\n",
    "def compute_gradient_derivatives(X, y, w, b): \n",
    "   \n",
    "    m,n = X.shape           \n",
    "    dj_dw = np.zeros((n,))  # J nin w ye gÃ¶re kÄ±smi tÃ¼revi\n",
    "    dj_db = 0.              # J nin b ye gÃ¶re kÄ±smi tÃ¼revi\n",
    "\n",
    "    for i in range(m):                             \n",
    "        \n",
    "        error = (np.dot(X[i], w) + b) - y[i]  \n",
    "        \n",
    "        for j in range(n):                         \n",
    "            \n",
    "            dj_dw[j] = dj_dw[j] + error * X[i, j]    \n",
    "            \n",
    "        dj_db = dj_db + error  \n",
    "        \n",
    "    dj_dw = dj_dw / m\n",
    "    \n",
    "    dj_db = dj_db / m  \n",
    "                                    \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5abf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19999999999999993,\n",
       " array([ 0.08080617, -0.05162175,  0.00049955,  0.17372699,  0.00215126,\n",
       "        -0.00789069]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient_derivatives(X_train,y_train,w_test,b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9a1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent ile J yi minimize edecek w,b deÄŸerlerini bulur, iterasyon sayÄ±sÄ±nÄ± ve w,b geÃ§miÅŸini gÃ¶sterir\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, compute_gradient_derivatives, alpha, num_iters): \n",
    "    \n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #fonksiyondaki global w deÄŸiÅŸkenin deÄŸiÅŸtirmemek iÃ§in\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # TÃ¼revleri hesapla ve ata\n",
    "        dj_db,dj_dw = compute_gradient_derivatives(X, y, w, b)\n",
    "\n",
    "        # Gradient Descent AlgoritmasÄ±, eÅŸ zamanlÄ± update ediliyor\n",
    "        w = w - alpha * dj_dw             \n",
    "        b = b - alpha * dj_db\n",
    "      \n",
    "        # Her iterasyon sonrasÄ± cost deÄŸerlerini kaydet\n",
    "        if i<100000:      # sÄ±nÄ±rlama \n",
    "            J_history.append(cost_function(X, y, w, b))\n",
    "\n",
    "        # yapÄ±lacak iterasyon sayÄ±sÄ±nÄ±n 10'da 1'ine gelince J_history'nin son elemanÄ±nÄ± yazdÄ±r\n",
    "        if i% math.ceil(num_iters / 10) == 0:  \n",
    "            print(f\"Iteration {i:}: Cost {J_history[-1]:}   \")\n",
    "        \n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ac70b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 0.4834028031299344   \n",
      "Iteration 100: Cost 0.2498703343180957   \n",
      "Iteration 200: Cost 0.24493996922060038   \n",
      "Iteration 300: Cost 0.24261342491483115   \n",
      "Iteration 400: Cost 0.2413145875892021   \n",
      "Iteration 500: Cost 0.24053721665385489   \n",
      "Iteration 600: Cost 0.24005626085250842   \n",
      "Iteration 700: Cost 0.23975374027910432   \n",
      "Iteration 800: Cost 0.23956151788779184   \n",
      "Iteration 900: Cost 0.2394383346302813   \n",
      "b,w found by gradient descent: 5.5335768173744554e-17,[ 0.01529997  0.28408847  0.34926467  0.22092324 -0.05261841 -0.00259832] \n",
      "prediction: -0.5061484898768139, target value: -0.8851608008511882\n",
      "prediction: -0.004972407630803005, target value: 1.7379468038539274\n",
      "prediction: 0.3850463165261524, target value: -0.8069422504090998\n",
      "prediction: -0.5342350732074809, target value: -0.4742719130844986\n",
      "prediction: -0.26993466784820846, target value: -0.1788646519326076\n",
      "prediction: 1.1308720468609708, target value: 1.6102302078119914\n",
      "prediction: -0.06206944698790311, target value: -0.8336879425965464\n",
      "prediction: 0.10671828364867661, target value: -0.1764597796349933\n",
      "prediction: -0.8155128167844069, target value: -0.901597316542022\n",
      "prediction: -0.6251898269573388, target value: -0.829297771466008\n"
     ]
    }
   ],
   "source": [
    "w_init = np.zeros(6)\n",
    "b_init = 0\n",
    "iterations = 1000\n",
    "alpha = 0.01\n",
    "\n",
    "w_final , b_final , J_hist = gradient_descent(\n",
    "                X_train, y_train, w_init, b_init , compute_cost, compute_gradient_derivatives, alpha, iterations)\n",
    "\n",
    "print(f\"b,w found by gradient descent: {b_final},{w_final} \")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc886771",
   "metadata": {},
   "source": [
    "# SonuÃ§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efe5c3",
   "metadata": {},
   "source": [
    "    Data lineer regresyona pek uygun olmamasÄ±na raÄŸmen devam etmek ve Ã¶zelliklerin katsayÄ±larÄ±nÄ± yorumlamak istedim. FarklÄ± learning rate ler, farklÄ± iterasyon sayÄ±larÄ± denememe raÄŸmen Ã§ok isabetli tahminler elde edemedim beklendiÄŸi Ã¼zere.\n",
    "\n",
    "    Pozitif katsayÄ±lar bÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe : PPG > MPG > PER > Age --> Buradan maaÅŸlara en Ã§ok etkisi olan Ã¶zelliklerin sÄ±rasÄ±yla 'MaÃ§ baÅŸÄ±na atÄ±lan sayÄ±' , 'MaÃ§ baÅŸÄ±na alÄ±nan sÃ¼re' , 'Oyuncu verimlilik puanÄ±' ve 'YaÅŸ' olduÄŸu sÃ¶ylenebilir.\n",
    "\n",
    "    Negatif Ã¶zelliklerde ise ; 'PFG' katsayÄ±sÄ± 'TOPG' e kÄ±yasla daha fazla olduÄŸu iÃ§in, maÃ§ baÅŸÄ±na yapÄ±lan faullerin maaÅŸlara top kayÄ±plarÄ±na gÃ¶re daha Ã§ok etki ettiÄŸi sÃ¶ylenebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ea594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
