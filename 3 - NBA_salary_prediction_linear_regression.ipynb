{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d0b8fc8",
   "metadata": {},
   "source": [
    "# Çoklu Lineer Regresyon ve Gradient Descent Algoritması ile tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f318509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math , copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671ce6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Stats_from</th>\n",
       "      <th>Age</th>\n",
       "      <th>MPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>PER</th>\n",
       "      <th>TOPG</th>\n",
       "      <th>PFG</th>\n",
       "      <th>2017_2018 Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quincy Acy</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.173081</td>\n",
       "      <td>0.564232</td>\n",
       "      <td>0.100335</td>\n",
       "      <td>0.480824</td>\n",
       "      <td>1.709538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.641793</td>\n",
       "      <td>0.264442</td>\n",
       "      <td>0.584383</td>\n",
       "      <td>0.230214</td>\n",
       "      <td>0.767744</td>\n",
       "      <td>22.471910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arron Afflalo</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.869415</td>\n",
       "      <td>0.425862</td>\n",
       "      <td>0.468514</td>\n",
       "      <td>0.253220</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>2.328652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexis Ajinca</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.348748</td>\n",
       "      <td>0.198451</td>\n",
       "      <td>0.541562</td>\n",
       "      <td>0.200671</td>\n",
       "      <td>0.625539</td>\n",
       "      <td>4.961798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.313858</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>0.730479</td>\n",
       "      <td>0.233868</td>\n",
       "      <td>0.638065</td>\n",
       "      <td>7.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Joe Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.203985</td>\n",
       "      <td>0.124940</td>\n",
       "      <td>0.443325</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.201530</td>\n",
       "      <td>1.471382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Nick Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.474377</td>\n",
       "      <td>0.241466</td>\n",
       "      <td>0.423174</td>\n",
       "      <td>0.121806</td>\n",
       "      <td>0.255022</td>\n",
       "      <td>5.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.857735</td>\n",
       "      <td>0.502137</td>\n",
       "      <td>0.634761</td>\n",
       "      <td>0.408468</td>\n",
       "      <td>0.686673</td>\n",
       "      <td>14.796348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.290711</td>\n",
       "      <td>0.599496</td>\n",
       "      <td>0.204234</td>\n",
       "      <td>0.769677</td>\n",
       "      <td>12.584270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Tyler Zeller</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.272318</td>\n",
       "      <td>0.201796</td>\n",
       "      <td>0.581864</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.445268</td>\n",
       "      <td>1.709538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player  Stats_from   Age       MPG       PPG       PER      TOPG  \\\n",
       "0        Quincy Acy      2016.0  0.30  0.355789  0.173081  0.564232  0.100335   \n",
       "1      Steven Adams      2016.0  0.15  0.641793  0.264442  0.584383  0.230214   \n",
       "2     Arron Afflalo      2016.0  0.55  0.869415  0.425862  0.468514  0.253220   \n",
       "3     Alexis Ajinca      2016.0  0.40  0.348748  0.198451  0.541562  0.200671   \n",
       "4      Cole Aldrich      2016.0  0.40  0.313858  0.181839  0.730479  0.233868   \n",
       "..              ...         ...   ...       ...       ...       ...       ...   \n",
       "340       Joe Young      2016.0  0.20  0.203985  0.124940  0.443325  0.176471   \n",
       "341      Nick Young      2016.0  0.55  0.474377  0.241466  0.423174  0.121806   \n",
       "342  Thaddeus Young      2016.0  0.40  0.857735  0.502137  0.634761  0.408468   \n",
       "343     Cody Zeller      2016.0  0.20  0.617600  0.290711  0.599496  0.204234   \n",
       "344    Tyler Zeller      2016.0  0.35  0.272318  0.201796  0.581864  0.168093   \n",
       "\n",
       "          PFG  2017_2018 Salary  \n",
       "0    0.480824          1.709538  \n",
       "1    0.767744         22.471910  \n",
       "2    0.550847          2.328652  \n",
       "3    0.625539          4.961798  \n",
       "4    0.638065          7.300000  \n",
       "..        ...               ...  \n",
       "340  0.201530          1.471382  \n",
       "341  0.255022          5.192000  \n",
       "342  0.686673         14.796348  \n",
       "343  0.769677         12.584270  \n",
       "344  0.445268          1.709538  \n",
       "\n",
       "[345 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba = pd.read_csv('vised_zscaled_nba_stats_salaries_2017_2018.csv')\n",
    "\n",
    "nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e4613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>MPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>PER</th>\n",
       "      <th>TOPG</th>\n",
       "      <th>PFG</th>\n",
       "      <th>2017_2018 Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.173081</td>\n",
       "      <td>0.564232</td>\n",
       "      <td>0.100335</td>\n",
       "      <td>0.480824</td>\n",
       "      <td>1.709538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.641793</td>\n",
       "      <td>0.264442</td>\n",
       "      <td>0.584383</td>\n",
       "      <td>0.230214</td>\n",
       "      <td>0.767744</td>\n",
       "      <td>22.471910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.869415</td>\n",
       "      <td>0.425862</td>\n",
       "      <td>0.468514</td>\n",
       "      <td>0.253220</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>2.328652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.348748</td>\n",
       "      <td>0.198451</td>\n",
       "      <td>0.541562</td>\n",
       "      <td>0.200671</td>\n",
       "      <td>0.625539</td>\n",
       "      <td>4.961798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.313858</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>0.730479</td>\n",
       "      <td>0.233868</td>\n",
       "      <td>0.638065</td>\n",
       "      <td>7.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.203985</td>\n",
       "      <td>0.124940</td>\n",
       "      <td>0.443325</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.201530</td>\n",
       "      <td>1.471382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.474377</td>\n",
       "      <td>0.241466</td>\n",
       "      <td>0.423174</td>\n",
       "      <td>0.121806</td>\n",
       "      <td>0.255022</td>\n",
       "      <td>5.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.857735</td>\n",
       "      <td>0.502137</td>\n",
       "      <td>0.634761</td>\n",
       "      <td>0.408468</td>\n",
       "      <td>0.686673</td>\n",
       "      <td>14.796348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.290711</td>\n",
       "      <td>0.599496</td>\n",
       "      <td>0.204234</td>\n",
       "      <td>0.769677</td>\n",
       "      <td>12.584270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.272318</td>\n",
       "      <td>0.201796</td>\n",
       "      <td>0.581864</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.445268</td>\n",
       "      <td>1.709538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age       MPG       PPG       PER      TOPG       PFG  2017_2018 Salary\n",
       "0    0.30  0.355789  0.173081  0.564232  0.100335  0.480824          1.709538\n",
       "1    0.15  0.641793  0.264442  0.584383  0.230214  0.767744         22.471910\n",
       "2    0.55  0.869415  0.425862  0.468514  0.253220  0.550847          2.328652\n",
       "3    0.40  0.348748  0.198451  0.541562  0.200671  0.625539          4.961798\n",
       "4    0.40  0.313858  0.181839  0.730479  0.233868  0.638065          7.300000\n",
       "..    ...       ...       ...       ...       ...       ...               ...\n",
       "340  0.20  0.203985  0.124940  0.443325  0.176471  0.201530          1.471382\n",
       "341  0.55  0.474377  0.241466  0.423174  0.121806  0.255022          5.192000\n",
       "342  0.40  0.857735  0.502137  0.634761  0.408468  0.686673         14.796348\n",
       "343  0.20  0.617600  0.290711  0.599496  0.204234  0.769677         12.584270\n",
       "344  0.35  0.272318  0.201796  0.581864  0.168093  0.445268          1.709538\n",
       "\n",
       "[345 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.drop(columns=['Player', 'Stats_from'], axis=1, inplace=True)\n",
    "\n",
    "nba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbb497",
   "metadata": {},
   "source": [
    "# Training datasını load etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d491b7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = nba['2017_2018 Salary']\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a0a7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_X = nba.drop('2017_2018 Salary',axis = 1)\n",
    "\n",
    "X_train = nba_X.to_numpy()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f02ac3",
   "metadata": {},
   "source": [
    "# Cost Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688486fa",
   "metadata": {},
   "source": [
    "    J(w,b) = 1/2m( f_wb(x ^ i) - y ^ i) ^ 2  ;  i = 0..m - 1\n",
    "\n",
    "    ve f_wb(x) = w * x[i] + b olmak üzere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e52528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           \n",
    "        cost += (f_wb_i - y[i])**2     \n",
    "    \n",
    "    cost /= (2 * m)                      \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59e2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.805756893464675"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_test = 0.2\n",
    "w_test = np.array([0.1 , 0.2 , 0.22 , 0.5 , -0.025 , -0.01])\n",
    "compute_cost(X_train,y_train,w_test,b_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42164bad",
   "metadata": {},
   "source": [
    "# Gradient Descent Algoritması:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28993eaf",
   "metadata": {},
   "source": [
    "yakınsama olana kadar tekrar et : {\n",
    "\n",
    "    w_j = w_j - a * (dJ(w,b) / dw_j)  ; j = 0..n - 1 (n = feature sayısı , a = learning rate alpha)\n",
    "\n",
    "    b = b - a * (dJ(w,b) / db)                     (w_j ve b aynı anda update edilecek(simultaneously))\n",
    "\n",
    "}\n",
    "\n",
    "ve \n",
    "\n",
    "    (dJ(w,b) / dw_j) = 1/m( f_wb(x ^ i) - y ^ i)x_j ^ i  ; i = 0..m - 1\n",
    "\n",
    "    (dJ(w,b) / db) =  1/m( f_wb(x ^ i) - y ^ i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "954e0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent formüllerindeki türevli kısımları hesaplar\n",
    "\n",
    "def compute_gradient_derivatives(X, y, w, b): \n",
    "   \n",
    "    m,n = X.shape           \n",
    "    dj_dw = np.zeros((n,))  # J nin w ye göre kısmi türevi\n",
    "    dj_db = 0.              # J nin b ye göre kısmi türevi\n",
    "\n",
    "    for i in range(m):                             \n",
    "        \n",
    "        error = (np.dot(X[i], w) + b) - y[i]  \n",
    "        \n",
    "        for j in range(n):                         \n",
    "            \n",
    "            dj_dw[j] = dj_dw[j] + error * X[i, j]    \n",
    "            \n",
    "        dj_db = dj_db + error  \n",
    "        \n",
    "    dj_dw = dj_dw / m\n",
    "    \n",
    "    dj_db = dj_db / m  \n",
    "                                    \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5abf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.023162285520222,\n",
       " array([-3.00178639, -5.81837496, -3.66659903, -5.00644721, -3.06875504,\n",
       "        -4.81854152]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient_derivatives(X_train,y_train,w_test,b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9a1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent ile J yi minimize edecek w,b değerlerini bulur, iterasyon sayısını ve w,b geçmişini gösterir\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, compute_gradient_derivatives, alpha, num_iters): \n",
    "    \n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #fonksiyondaki global w değişkenin değiştirmemek için\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Türevleri hesapla ve ata\n",
    "        dj_db,dj_dw = compute_gradient_derivatives(X, y, w, b)\n",
    "\n",
    "        # Gradient Descent Algoritması, eş zamanlı update ediliyor\n",
    "        w = w - alpha * dj_dw             \n",
    "        b = b - alpha * dj_db\n",
    "      \n",
    "        # Her iterasyon sonrası cost değerlerini kaydet\n",
    "        if i<100001:      # sınırlama \n",
    "            J_history.append(cost_function(X, y, w, b))\n",
    "\n",
    "        # yapılacak iterasyon sayısının 10'da 1'ine gelince J_history'nin son elemanını yazdır\n",
    "        if i% math.ceil(num_iters / 10) == 0:  \n",
    "            print(f\"Iteration {i}: Cost {J_history[-1]}\")\n",
    "        elif num_iters == len(J_history):\n",
    "            print(f\"Iteration {num_iters}: Cost {J_history[-1]}\")\n",
    "        \n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ac70b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 67.25141478915107\n",
      "Iteration 100: Cost 23.86883089952494\n",
      "Iteration 200: Cost 22.54555596284038\n",
      "Iteration 300: Cost 21.734710867181846\n",
      "Iteration 400: Cost 21.0326188342363\n",
      "Iteration 500: Cost 20.421426671017876\n",
      "Iteration 600: Cost 19.888805043300195\n",
      "Iteration 700: Cost 19.424138640992116\n",
      "Iteration 800: Cost 19.018262734743832\n",
      "Iteration 900: Cost 18.663264078213857\n",
      "Iteration 1000: Cost 18.35522100877221\n",
      "b,w found by gradient descent: -0.49194152319425777,[0.3251994  5.99537908 5.79845497 2.99565515 3.68121144 2.41273204] \n",
      "prediction: 6.0, target value: 1.7\n",
      "prediction: 9.4, target value: 22.5\n",
      "prediction: 11.0, target value: 2.3\n",
      "prediction: 6.8, target value: 5.0\n",
      "prediction: 7.2, target value: 7.3\n",
      "prediction: 12.6, target value: 21.5\n",
      "prediction: 9.6, target value: 2.1\n",
      "prediction: 10.1, target value: 7.3\n",
      "prediction: 4.3, target value: 1.6\n",
      "prediction: 5.7, target value: 2.2\n"
     ]
    }
   ],
   "source": [
    "w_init = np.zeros(6)\n",
    "b_init = 0\n",
    "iterations = 1000\n",
    "alpha = 0.01\n",
    "\n",
    "w_final , b_final , J_hist = gradient_descent(\n",
    "                X_train, y_train, w_init, b_init , compute_cost, compute_gradient_derivatives, alpha, iterations)\n",
    "\n",
    "print(f\"b,w found by gradient descent: {b_final},{w_final} \")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.1f}, target value: {y_train[i]:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc886771",
   "metadata": {},
   "source": [
    "# Sonuç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efe5c3",
   "metadata": {},
   "source": [
    "    Bazı feature'lar lineer regresyona pek uygun olmamasına rağmen devam etmek ve özelliklerin katsayılarını yorumlamak istedim. Farklı learning rate ler, farklı iterasyon sayıları denememe rağmen çok isabetli denebilecek tahminler elde edemedim beklendiği üzere.\n",
    "\n",
    "    Pozitif katsayılar büyükten küçüğe : PPG > MPG > PER > Age --> Buradan maaşlara en çok etkisi olan özelliklerin sırasıyla 'Maç başına atılan sayı' , 'Maç başına alınan süre' , 'Oyuncu verimlilik puanı' ve 'Yaş' olduğu söylenebilir.\n",
    "\n",
    "    Negatif özelliklerde ise ; 'PFG' katsayısı 'TOPG' e kıyasla daha fazla olduğu için, maç başına yapılan faullerin maaşlara top kayıplarına göre daha çok etki ettiği söylenebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ea594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
